{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"onemetric Installation Install onemetric from PyPI (recommended): pip install --upgrade pip pip install onemetric Install onemetric from the GitHub source: git clone https://github.com/SkalskiP/onemetric.git cd onemetric python setup.py install Example Figure 1. Dataset sample, blue - ground-truth and red - detection. Calculate mAP@0.5 >>> from onemetric.cv.loaders import YOLOLoader >>> from onemetric.cv.object_detection import MeanAveragePrecision >>> model = load_model ( ... ) # model-specific loading method >>> data_set = YOLOLoader ( ... images_dir_path = DATA_SET_IMAGES_PATH , ... annotations_dir_path = DATA_SET_ANNOTATIONS_PATH ... ) . load () >>> true_batches , detection_batches = [], [] >>> for entry in data_set : >>> detections = model ( entry . get_image ()) # model-specific prediction method >>> true_batches . append ( entry . get_annotations ()) >>> detection_batches . append ( detections ) >>> mean_average_precision = MeanAveragePrecision . from_detections ( ... true_batches = true_batches , ... detection_batches = detection_batches , ... num_classes = 12 , ... iou_threshold = 0.5 ... ) >>> mean_average_precision . value 0.61 Calculate Confusion Matrix >>> confusion_matrix = ConfusionMatrix . from_detections ( ... true_batches = true_batches , ... detection_batches = detection_batches , ... num_classes = 12 ... ) >>> confusion_matrix . plot ( CONFUSION_MATRIX_TARGET_PATH , class_names = CLASS_NAMES ) Figure 2. Create confusion matrix chart Documentation The official documentation is hosted on Github Pages: https://skalskip.github.io/onemetric Contribute Feel free to file issues or pull requests . Let us know what metrics should be part of onemetric! Citation Please cite onemetric in your publications if this is useful for your research. Here is an example BibTeX entry: @MISC { onemetric , author = {Piotr Skalski} , title = {{onemetric}} , howpublished = \"\\url{https://github.com/SkalskiP/onemetric/}\" , year = {2021} , } License This project is licensed under the BSD 3 - see the LICENSE file for details.","title":"Home"},{"location":"#installation","text":"Install onemetric from PyPI (recommended): pip install --upgrade pip pip install onemetric Install onemetric from the GitHub source: git clone https://github.com/SkalskiP/onemetric.git cd onemetric python setup.py install","title":"Installation"},{"location":"#example","text":"Figure 1. Dataset sample, blue - ground-truth and red - detection.","title":"Example"},{"location":"#calculate-map05","text":">>> from onemetric.cv.loaders import YOLOLoader >>> from onemetric.cv.object_detection import MeanAveragePrecision >>> model = load_model ( ... ) # model-specific loading method >>> data_set = YOLOLoader ( ... images_dir_path = DATA_SET_IMAGES_PATH , ... annotations_dir_path = DATA_SET_ANNOTATIONS_PATH ... ) . load () >>> true_batches , detection_batches = [], [] >>> for entry in data_set : >>> detections = model ( entry . get_image ()) # model-specific prediction method >>> true_batches . append ( entry . get_annotations ()) >>> detection_batches . append ( detections ) >>> mean_average_precision = MeanAveragePrecision . from_detections ( ... true_batches = true_batches , ... detection_batches = detection_batches , ... num_classes = 12 , ... iou_threshold = 0.5 ... ) >>> mean_average_precision . value 0.61","title":"Calculate mAP@0.5"},{"location":"#calculate-confusion-matrix","text":">>> confusion_matrix = ConfusionMatrix . from_detections ( ... true_batches = true_batches , ... detection_batches = detection_batches , ... num_classes = 12 ... ) >>> confusion_matrix . plot ( CONFUSION_MATRIX_TARGET_PATH , class_names = CLASS_NAMES ) Figure 2. Create confusion matrix chart","title":"Calculate Confusion Matrix"},{"location":"#documentation","text":"The official documentation is hosted on Github Pages: https://skalskip.github.io/onemetric","title":"Documentation"},{"location":"#contribute","text":"Feel free to file issues or pull requests . Let us know what metrics should be part of onemetric!","title":"Contribute"},{"location":"#citation","text":"Please cite onemetric in your publications if this is useful for your research. Here is an example BibTeX entry: @MISC { onemetric , author = {Piotr Skalski} , title = {{onemetric}} , howpublished = \"\\url{https://github.com/SkalskiP/onemetric/}\" , year = {2021} , }","title":"Citation"},{"location":"#license","text":"This project is licensed under the BSD 3 - see the LICENSE file for details.","title":"License"},{"location":"CONTRIBUTING/","text":"Contribution Guide We welcome any contributions whether it is: Submitting feedback Fixing bugs Or implementing a new feature. Please read this guide before making any contributions. Submit Feedback The feedback should be submitted by creating an issue on GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels. Fix Bugs You may look through the GitHub issues for bugs. Implement Features You may look through the GitHub issues for feature requests. Pull Requests (PR) Fork the repository and create a new branch from the develop branch. For bug fixes, add new tests and for new features, please add changes to the documentation. Do a PR from your new branch to our develop branch of the original onemetric repo. Documentation Make sure any new function or class you introduce has proper docstrings. Testing We use pytest for our testing. Make sure to write tests for any new feature and/or bug fixes. Main Contributor List We maintain a list of main contributors to appreciate all the contributions.","title":"Contribution Guide"},{"location":"CONTRIBUTING/#contribution-guide","text":"We welcome any contributions whether it is: Submitting feedback Fixing bugs Or implementing a new feature. Please read this guide before making any contributions.","title":"Contribution Guide"},{"location":"CONTRIBUTING/#submit-feedback","text":"The feedback should be submitted by creating an issue on GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels.","title":"Submit Feedback"},{"location":"CONTRIBUTING/#fix-bugs","text":"You may look through the GitHub issues for bugs.","title":"Fix Bugs"},{"location":"CONTRIBUTING/#implement-features","text":"You may look through the GitHub issues for feature requests.","title":"Implement Features"},{"location":"CONTRIBUTING/#pull-requests-pr","text":"Fork the repository and create a new branch from the develop branch. For bug fixes, add new tests and for new features, please add changes to the documentation. Do a PR from your new branch to our develop branch of the original onemetric repo.","title":"Pull Requests (PR)"},{"location":"CONTRIBUTING/#documentation","text":"Make sure any new function or class you introduce has proper docstrings.","title":"Documentation"},{"location":"CONTRIBUTING/#testing","text":"We use pytest for our testing. Make sure to write tests for any new feature and/or bug fixes.","title":"Testing"},{"location":"CONTRIBUTING/#main-contributor-list","text":"We maintain a list of main contributors to appreciate all the contributions.","title":"Main Contributor List"},{"location":"LICENSE/","text":"BSD 3-Clause License Copyright (c) 2021, Piotr Skalski All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"const/","text":"","title":"Const"},{"location":"cv/loaders/base/","text":"class DataSetElement get_image def get_image () get_image_path def get_image_path () get_annotations def get_annotations () class DataSetLoader load def load () class DataSetEntry","title":"Base"},{"location":"cv/loaders/base/#class-datasetelement","text":"","title":"class DataSetElement"},{"location":"cv/loaders/base/#get_image","text":"def get_image ()","title":"get_image"},{"location":"cv/loaders/base/#get_image_path","text":"def get_image_path ()","title":"get_image_path"},{"location":"cv/loaders/base/#get_annotations","text":"def get_annotations ()","title":"get_annotations"},{"location":"cv/loaders/base/#class-datasetloader","text":"","title":"class DataSetLoader"},{"location":"cv/loaders/base/#load","text":"def load ()","title":"load"},{"location":"cv/loaders/base/#class-datasetentry","text":"","title":"class DataSetEntry"},{"location":"cv/loaders/yolo/","text":"class YOLOElement TODO __init__ def __init__ ( image , image_path , annotations ) TODO get_image def get_image () TODO get_image_path def get_image_path () TODO get_annotations def get_annotations () TODO class YOLOLoader TODO __init__ def __init__ ( images_dir_path , annotations_dir_path ) TODO load def load () TODO","title":"Yolo"},{"location":"cv/loaders/yolo/#class-yoloelement","text":"TODO","title":"class YOLOElement"},{"location":"cv/loaders/yolo/#__init__","text":"def __init__ ( image , image_path , annotations ) TODO","title":"__init__"},{"location":"cv/loaders/yolo/#get_image","text":"def get_image () TODO","title":"get_image"},{"location":"cv/loaders/yolo/#get_image_path","text":"def get_image_path () TODO","title":"get_image_path"},{"location":"cv/loaders/yolo/#get_annotations","text":"def get_annotations () TODO","title":"get_annotations"},{"location":"cv/loaders/yolo/#class-yololoader","text":"TODO","title":"class YOLOLoader"},{"location":"cv/loaders/yolo/#__init___1","text":"def __init__ ( images_dir_path , annotations_dir_path ) TODO","title":"__init__"},{"location":"cv/loaders/yolo/#load","text":"def load () TODO","title":"load"},{"location":"cv/object_detection/average_precision/","text":"class AveragePrecision from_detections def from_detections ( cls , true_batches , detection_batches , class_idx , iou_threshold ) Calculate average precision (AP) metric based on ground-true and detected objects across all images in concerned dataset. Args true_batches : List[np.ndarray] representing ground-truth objects across all images in concerned dataset. Each element of true_batches list describe single image and has shape = (N, 5) where N is number of ground-truth objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class) . detection_batches : List[np.ndarray] representing detected objects across all images in concerned dataset. Each element of detection_batches list describe single image and has shape = (M, 6) where M is number of detected objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class, conf) . class_idx : int index of the class for which you want to calculate average precision (AP). iou_threshold : float detection iou threshold between 0 and 1. Detections with lower iou will be classified as FP. from_precision_recall def from_precision_recall ( cls , recall , precision , class_idx , iou_threshold ) Calculate average precision (AP) metric based on given precision/recall curve.","title":"Average precision"},{"location":"cv/object_detection/average_precision/#class-averageprecision","text":"","title":"class AveragePrecision"},{"location":"cv/object_detection/average_precision/#from_detections","text":"def from_detections ( cls , true_batches , detection_batches , class_idx , iou_threshold ) Calculate average precision (AP) metric based on ground-true and detected objects across all images in concerned dataset.","title":"from_detections"},{"location":"cv/object_detection/average_precision/#args","text":"true_batches : List[np.ndarray] representing ground-truth objects across all images in concerned dataset. Each element of true_batches list describe single image and has shape = (N, 5) where N is number of ground-truth objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class) . detection_batches : List[np.ndarray] representing detected objects across all images in concerned dataset. Each element of detection_batches list describe single image and has shape = (M, 6) where M is number of detected objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class, conf) . class_idx : int index of the class for which you want to calculate average precision (AP). iou_threshold : float detection iou threshold between 0 and 1. Detections with lower iou will be classified as FP.","title":"Args"},{"location":"cv/object_detection/average_precision/#from_precision_recall","text":"def from_precision_recall ( cls , recall , precision , class_idx , iou_threshold ) Calculate average precision (AP) metric based on given precision/recall curve.","title":"from_precision_recall"},{"location":"cv/object_detection/confusion_matrix/","text":"class ConfusionMatrix Calculate and visualize confusion matrix of Object Detection model. from_detections def from_detections ( cls , true_batches , detection_batches , num_classes , conf_threshold , iou_threshold ) Calculate confusion matrix based on ground-true and detected objects across all images in concerned dataset. Args true_batches : List[np.ndarray] representing ground-truth objects across all images in concerned dataset. Each element of true_batches list describe single image and has shape = (N, 5) where N is number of ground-truth objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class) . detection_batches : List[np.ndarray] representing detected objects across all images in concerned dataset. Each element of detection_batches list describe single image and has shape = (M, 6) where M is number of detected objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class, conf) . num_classes : int number of classes detected by model. conf_threshold : float detection confidence threshold between 0 and 1. Detections with lower confidence will be excluded. iou_threshold : float detection iou threshold between 0 and 1. Detections with lower iou will be classified as FP. Returns confusion_matrix : ConfusionMatrix object raw confusion matrix 2d np.ndarray . Example usage >>> import numpy as np >>> from onemetric.cv.object_detection import ConfusionMatrix >>> true_batches = [ ... np . array ([ ... [ 0.0 , 0.0 , 3.0 , 3.0 , 1 ], ... [ 2.0 , 2.0 , 5.0 , 5.0 , 1 ], ... [ 6.0 , 1.0 , 8.0 , 3.0 , 2 ], ... ]), ... np . array ([ ... [ 1.0 , 1.0 , 2.0 , 2.0 , 2 ], ... ]), ... ] >>> detection_batches = [ ... np . array ([ ... [ 0.0 , 0.0 , 3.0 , 3.0 , 1 , 0.9 ], ... [ 0.1 , 0.1 , 3.0 , 3.0 , 0 , 0.9 ], ... [ 6.0 , 1.0 , 8.0 , 3.0 , 1 , 0.8 ], ... [ 1.0 , 6.0 , 2.0 , 7.0 , 1 , 0.8 ], ... ]), ... np . array ([ ... [ 1.0 , 1.0 , 2.0 , 2.0 , 2 , 0.8 ], ... ]), ... ] >>> confusion_matrix = ConfusionMatrix . from_detections ( ... true_batches = true_batches , ... detection_batches = detection_batches , ... num_classes = 3 ... ) >>> confusion_matrix . matrix ... array ([ ... [ 0. , 0. , 0. , 0. ], ... [ 0. , 1. , 0. , 1. ], ... [ 0. , 1. , 1. , 0. ], ... [ 1. , 1. , 0. , 0. ] ... ]) plot def plot ( target_path , title , class_names , normalize ) Create confusion matrix plot and save it at selected location. Args target_path : str selected target location of confusion matrix plot. title : Optional[str] title displayed at the top of the confusion matrix plot. Default None . class_names : Optional[List[str]] list of class names detected my model. If non given class indexes will be used. Default None . normalize : bool if set to False chart will display absolute number of detections falling into given category. Otherwise percentage of detections will be displayed.","title":"Confusion Matrix"},{"location":"cv/object_detection/confusion_matrix/#class-confusionmatrix","text":"Calculate and visualize confusion matrix of Object Detection model.","title":"class ConfusionMatrix"},{"location":"cv/object_detection/confusion_matrix/#from_detections","text":"def from_detections ( cls , true_batches , detection_batches , num_classes , conf_threshold , iou_threshold ) Calculate confusion matrix based on ground-true and detected objects across all images in concerned dataset.","title":"from_detections"},{"location":"cv/object_detection/confusion_matrix/#args","text":"true_batches : List[np.ndarray] representing ground-truth objects across all images in concerned dataset. Each element of true_batches list describe single image and has shape = (N, 5) where N is number of ground-truth objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class) . detection_batches : List[np.ndarray] representing detected objects across all images in concerned dataset. Each element of detection_batches list describe single image and has shape = (M, 6) where M is number of detected objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class, conf) . num_classes : int number of classes detected by model. conf_threshold : float detection confidence threshold between 0 and 1. Detections with lower confidence will be excluded. iou_threshold : float detection iou threshold between 0 and 1. Detections with lower iou will be classified as FP.","title":"Args"},{"location":"cv/object_detection/confusion_matrix/#returns","text":"confusion_matrix : ConfusionMatrix object raw confusion matrix 2d np.ndarray .","title":"Returns"},{"location":"cv/object_detection/confusion_matrix/#example-usage","text":">>> import numpy as np >>> from onemetric.cv.object_detection import ConfusionMatrix >>> true_batches = [ ... np . array ([ ... [ 0.0 , 0.0 , 3.0 , 3.0 , 1 ], ... [ 2.0 , 2.0 , 5.0 , 5.0 , 1 ], ... [ 6.0 , 1.0 , 8.0 , 3.0 , 2 ], ... ]), ... np . array ([ ... [ 1.0 , 1.0 , 2.0 , 2.0 , 2 ], ... ]), ... ] >>> detection_batches = [ ... np . array ([ ... [ 0.0 , 0.0 , 3.0 , 3.0 , 1 , 0.9 ], ... [ 0.1 , 0.1 , 3.0 , 3.0 , 0 , 0.9 ], ... [ 6.0 , 1.0 , 8.0 , 3.0 , 1 , 0.8 ], ... [ 1.0 , 6.0 , 2.0 , 7.0 , 1 , 0.8 ], ... ]), ... np . array ([ ... [ 1.0 , 1.0 , 2.0 , 2.0 , 2 , 0.8 ], ... ]), ... ] >>> confusion_matrix = ConfusionMatrix . from_detections ( ... true_batches = true_batches , ... detection_batches = detection_batches , ... num_classes = 3 ... ) >>> confusion_matrix . matrix ... array ([ ... [ 0. , 0. , 0. , 0. ], ... [ 0. , 1. , 0. , 1. ], ... [ 0. , 1. , 1. , 0. ], ... [ 1. , 1. , 0. , 0. ] ... ])","title":"Example usage"},{"location":"cv/object_detection/confusion_matrix/#plot","text":"def plot ( target_path , title , class_names , normalize ) Create confusion matrix plot and save it at selected location.","title":"plot"},{"location":"cv/object_detection/confusion_matrix/#args_1","text":"target_path : str selected target location of confusion matrix plot. title : Optional[str] title displayed at the top of the confusion matrix plot. Default None . class_names : Optional[List[str]] list of class names detected my model. If non given class indexes will be used. Default None . normalize : bool if set to False chart will display absolute number of detections falling into given category. Otherwise percentage of detections will be displayed.","title":"Args"},{"location":"cv/object_detection/mean_average_precision/","text":"class MeanAveragePrecision from_detections def from_detections ( cls , true_batches , detection_batches , num_classes , iou_threshold ) Calculate mean average precision (mAP) metric for selected iou_threshold based on true_batches and detection_batches . Args true_batches : List[np.ndarray] representing ground-truth objects across all images in concerned dataset. Each element of true_batches list describe single image and has shape = (N, 5) where N is number of ground-truth objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class) . detection_batches : List[np.ndarray] representing detected objects across all images in concerned dataset. Each element of detection_batches list describe single image and has shape = (M, 6) where M is number of detected objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class, conf) . num_classes : int number of classes detected by model. iou_threshold : float detection iou threshold between 0 and 1. Detections with lower iou will be classified as FP. Returns mean_average_precision : MeanAveragePrecision object containing mAP value calculated for provided iou_threshold as well as AveragePrecision object calculated for each individual class. Example usage >>> import numpy as np >>> from onemetric.cv.object_detection import MeanAveragePrecision >>> true_batches = [ ... np . array ([ ... [ 0.0 , 0.0 , 3.0 , 3.0 , 1 ], ... [ 2.0 , 2.0 , 5.0 , 5.0 , 1 ], ... [ 6.0 , 1.0 , 8.0 , 3.0 , 2 ], ... ]), ... np . array ([ ... [ 1.0 , 1.0 , 2.0 , 2.0 , 2 ], ... ]), ... ] >>> detection_batches = [ ... np . array ([ ... [ 0.0 , 0.0 , 3.0 , 3.0 , 1 , 0.9 ], ... [ 0.1 , 0.1 , 3.0 , 3.0 , 0 , 0.9 ], ... [ 6.0 , 1.0 , 8.0 , 3.0 , 1 , 0.8 ], ... [ 1.0 , 6.0 , 2.0 , 7.0 , 1 , 0.8 ], ... ]), ... np . array ([ ... [ 1.0 , 1.0 , 2.0 , 2.0 , 2 , 0.8 ], ... ]), ... ] >>> mean_average_precision = MeanAveragePrecision . from_detections ( ... true_batches = true_batches , ... detection_batches = detection_batches , ... num_classes = 3 ... ) >>> mean_average_precision . value ... 0.4444444444444444 plot def plot ( target_path , title , class_names ) Create mean average precision plot and save it at selected location. Args target_path : str selected target location of confusion matrix plot. title : Optional[str] title displayed at the top of the confusion matrix plot. Default None . class_names : Optional[List[str]] list of class names detected my model. If non given class indexes will be used. Default None .","title":"Mean Average Precision"},{"location":"cv/object_detection/mean_average_precision/#class-meanaverageprecision","text":"","title":"class MeanAveragePrecision"},{"location":"cv/object_detection/mean_average_precision/#from_detections","text":"def from_detections ( cls , true_batches , detection_batches , num_classes , iou_threshold ) Calculate mean average precision (mAP) metric for selected iou_threshold based on true_batches and detection_batches .","title":"from_detections"},{"location":"cv/object_detection/mean_average_precision/#args","text":"true_batches : List[np.ndarray] representing ground-truth objects across all images in concerned dataset. Each element of true_batches list describe single image and has shape = (N, 5) where N is number of ground-truth objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class) . detection_batches : List[np.ndarray] representing detected objects across all images in concerned dataset. Each element of detection_batches list describe single image and has shape = (M, 6) where M is number of detected objects. Each row is expected to be in (x_min, y_min, x_max, y_max, class, conf) . num_classes : int number of classes detected by model. iou_threshold : float detection iou threshold between 0 and 1. Detections with lower iou will be classified as FP.","title":"Args"},{"location":"cv/object_detection/mean_average_precision/#returns","text":"mean_average_precision : MeanAveragePrecision object containing mAP value calculated for provided iou_threshold as well as AveragePrecision object calculated for each individual class.","title":"Returns"},{"location":"cv/object_detection/mean_average_precision/#example-usage","text":">>> import numpy as np >>> from onemetric.cv.object_detection import MeanAveragePrecision >>> true_batches = [ ... np . array ([ ... [ 0.0 , 0.0 , 3.0 , 3.0 , 1 ], ... [ 2.0 , 2.0 , 5.0 , 5.0 , 1 ], ... [ 6.0 , 1.0 , 8.0 , 3.0 , 2 ], ... ]), ... np . array ([ ... [ 1.0 , 1.0 , 2.0 , 2.0 , 2 ], ... ]), ... ] >>> detection_batches = [ ... np . array ([ ... [ 0.0 , 0.0 , 3.0 , 3.0 , 1 , 0.9 ], ... [ 0.1 , 0.1 , 3.0 , 3.0 , 0 , 0.9 ], ... [ 6.0 , 1.0 , 8.0 , 3.0 , 1 , 0.8 ], ... [ 1.0 , 6.0 , 2.0 , 7.0 , 1 , 0.8 ], ... ]), ... np . array ([ ... [ 1.0 , 1.0 , 2.0 , 2.0 , 2 , 0.8 ], ... ]), ... ] >>> mean_average_precision = MeanAveragePrecision . from_detections ( ... true_batches = true_batches , ... detection_batches = detection_batches , ... num_classes = 3 ... ) >>> mean_average_precision . value ... 0.4444444444444444","title":"Example usage"},{"location":"cv/object_detection/mean_average_precision/#plot","text":"def plot ( target_path , title , class_names ) Create mean average precision plot and save it at selected location.","title":"plot"},{"location":"cv/object_detection/mean_average_precision/#args_1","text":"target_path : str selected target location of confusion matrix plot. title : Optional[str] title displayed at the top of the confusion matrix plot. Default None . class_names : Optional[List[str]] list of class names detected my model. If non given class indexes will be used. Default None .","title":"Args"},{"location":"cv/utils/iou/","text":"box_iou def box_iou ( box_true , box_detection ) Compute Intersection over Union of two bounding boxes - box_true and box_detection . Both boxes are expected to be tuples in (x_min, y_min, x_max, y_max) format. Args box_true : tuple representing ground-truth bounding boxes. box_detection : tuple representing detection bounding boxes. Returns iou : float value between 0 and 1. None if union is equal to 0. Example usage >>> from onemetric.cv.utils.iou import box_iou >>> iou = box_iou_batch ( ... boxes_true = ( 0. , 0. , 1. , 1. ), ... boxes_detection = ( 0.25 , 0. , 1.25 , 1. ) ... ) >>> iou ... 0.6 box_iou_batch def box_iou_batch ( boxes_true , boxes_detection ) Compute Intersection over Union of two sets of bounding boxes - boxes_true and boxes_detection . Both sets of boxes are expected to be in (x_min, y_min, x_max, y_max) format. Args boxes_true : 2d np.ndarray representing ground-truth boxes. shape = (N, 4) where N is number of true objects. boxes_detection : 2d np.ndarray representing detection boxes. shape = (M, 4) where M is number of detected objects. Returns iou : 2d np.ndarray representing pairwise IoU of boxes from boxes_true and boxes_detection . shape = (N, M) where N is number of true objects and M is number of detected objects. Example usage >>> import numpy as np >>> from onemetric.cv.utils.iou import box_iou_batch >>> boxes_true = np . array ([ ... [ 0. , 0. , 1. , 1. ], ... [ 2. , 2. , 2.5 , 2.5 ] ... ]) >>> boxes_detection = np . array ([ ... [ 0. , 0. , 1. , 1. ], ... [ 2. , 2. , 2.5 , 2.5 ] ... ]) >>> iou = box_iou_batch ( boxes_true = boxes_true , boxes_detection = boxes_detection ) >>> iou ... np . array ([ ... [ 1. , 0. ], ... [ 0. , 1. ] ... ]) mask_iou def mask_iou ( mask_true , mask_detection ) Compute Intersection over Union of two masks - mask_true and mask_detection. Shapes of mask_true and mask_detection should be identical. Both arrays are expected to be np.uint8 type and contain binary values (0 or 1). Args mask_true : 2d np.ndarray representing ground-truth mask. mask_detection : 2d np.ndarray representing detection mask. Returns iou : float value between 0 and 1. None if union is equal to 0. Example usage >>> import numpy as np >>> from onemetric.cv.utils.iou import mask_iou >>> full_mask = np . ones (( 10 , 10 )) . astype ( 'uint8' ) >>> quarter_mask = np . zeros (( 10 , 10 )) . astype ( 'uint8' ) >>> quarter_mask [ 0 : 5 , 0 : 5 ] = 1 >>> iou = mask_iou ( mask_true = full_mask , mask_detection = quarter_mask ) >>> iou ... 0.25","title":"Intersection over Union"},{"location":"cv/utils/iou/#box_iou","text":"def box_iou ( box_true , box_detection ) Compute Intersection over Union of two bounding boxes - box_true and box_detection . Both boxes are expected to be tuples in (x_min, y_min, x_max, y_max) format.","title":"box_iou"},{"location":"cv/utils/iou/#args","text":"box_true : tuple representing ground-truth bounding boxes. box_detection : tuple representing detection bounding boxes.","title":"Args"},{"location":"cv/utils/iou/#returns","text":"iou : float value between 0 and 1. None if union is equal to 0.","title":"Returns"},{"location":"cv/utils/iou/#example-usage","text":">>> from onemetric.cv.utils.iou import box_iou >>> iou = box_iou_batch ( ... boxes_true = ( 0. , 0. , 1. , 1. ), ... boxes_detection = ( 0.25 , 0. , 1.25 , 1. ) ... ) >>> iou ... 0.6","title":"Example usage"},{"location":"cv/utils/iou/#box_iou_batch","text":"def box_iou_batch ( boxes_true , boxes_detection ) Compute Intersection over Union of two sets of bounding boxes - boxes_true and boxes_detection . Both sets of boxes are expected to be in (x_min, y_min, x_max, y_max) format.","title":"box_iou_batch"},{"location":"cv/utils/iou/#args_1","text":"boxes_true : 2d np.ndarray representing ground-truth boxes. shape = (N, 4) where N is number of true objects. boxes_detection : 2d np.ndarray representing detection boxes. shape = (M, 4) where M is number of detected objects.","title":"Args"},{"location":"cv/utils/iou/#returns_1","text":"iou : 2d np.ndarray representing pairwise IoU of boxes from boxes_true and boxes_detection . shape = (N, M) where N is number of true objects and M is number of detected objects.","title":"Returns"},{"location":"cv/utils/iou/#example-usage_1","text":">>> import numpy as np >>> from onemetric.cv.utils.iou import box_iou_batch >>> boxes_true = np . array ([ ... [ 0. , 0. , 1. , 1. ], ... [ 2. , 2. , 2.5 , 2.5 ] ... ]) >>> boxes_detection = np . array ([ ... [ 0. , 0. , 1. , 1. ], ... [ 2. , 2. , 2.5 , 2.5 ] ... ]) >>> iou = box_iou_batch ( boxes_true = boxes_true , boxes_detection = boxes_detection ) >>> iou ... np . array ([ ... [ 1. , 0. ], ... [ 0. , 1. ] ... ])","title":"Example usage"},{"location":"cv/utils/iou/#mask_iou","text":"def mask_iou ( mask_true , mask_detection ) Compute Intersection over Union of two masks - mask_true and mask_detection. Shapes of mask_true and mask_detection should be identical. Both arrays are expected to be np.uint8 type and contain binary values (0 or 1).","title":"mask_iou"},{"location":"cv/utils/iou/#args_2","text":"mask_true : 2d np.ndarray representing ground-truth mask. mask_detection : 2d np.ndarray representing detection mask.","title":"Args"},{"location":"cv/utils/iou/#returns_2","text":"iou : float value between 0 and 1. None if union is equal to 0.","title":"Returns"},{"location":"cv/utils/iou/#example-usage_2","text":">>> import numpy as np >>> from onemetric.cv.utils.iou import mask_iou >>> full_mask = np . ones (( 10 , 10 )) . astype ( 'uint8' ) >>> quarter_mask = np . zeros (( 10 , 10 )) . astype ( 'uint8' ) >>> quarter_mask [ 0 : 5 , 0 : 5 ] = 1 >>> iou = mask_iou ( mask_true = full_mask , mask_detection = quarter_mask ) >>> iou ... 0.25","title":"Example usage"},{"location":"cv/utils/validators/","text":"validate_true_batch def validate_true_batch ( true_batch ) validate_detection_batch def validate_detection_batch ( detection_batch ) validate_detections def validate_detections ( true_batches , detection_batches ) validate_precision_recall def validate_precision_recall ( recall , precision )","title":"Validators"},{"location":"cv/utils/validators/#validate_true_batch","text":"def validate_true_batch ( true_batch )","title":"validate_true_batch"},{"location":"cv/utils/validators/#validate_detection_batch","text":"def validate_detection_batch ( detection_batch )","title":"validate_detection_batch"},{"location":"cv/utils/validators/#validate_detections","text":"def validate_detections ( true_batches , detection_batches )","title":"validate_detections"},{"location":"cv/utils/validators/#validate_precision_recall","text":"def validate_precision_recall ( recall , precision )","title":"validate_precision_recall"},{"location":"utils/general/","text":"list_files_with_extension def list_files_with_extension ( root_path , extensions ) read_text_file_lines def read_text_file_lines ( file_path )","title":"General"},{"location":"utils/general/#list_files_with_extension","text":"def list_files_with_extension ( root_path , extensions )","title":"list_files_with_extension"},{"location":"utils/general/#read_text_file_lines","text":"def read_text_file_lines ( file_path )","title":"read_text_file_lines"}]}